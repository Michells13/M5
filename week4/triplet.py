# -*- coding: utf-8 -*-
"""TripletMarginLossMNIST.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/KevinMusgrave/pytorch-metric-learning/blob/master/examples/notebooks/TripletMarginLossMNIST.ipynb
"""


#dataset1 = datasets.MNIST(".", train=True, download=True, transform=transform)
#dataset2 = datasets.MNIST(".", train=False, transform=transform)
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import matplotlib.pyplot as plt


from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from pytorch_metric_learning import distances, losses, miners, reducers, testers
from pytorch_metric_learning.utils.accuracy_calculator import AccuracyCalculator
import torchvision.models as models
from torchvision.models import resnet18, ResNet18_Weights
import numpy as np
import random
from PIL import Image
import PIL.ImageOps    
import optuna
# Creating some helper functions




class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(3, 32, 3, 1)
        self.conv2 = nn.Conv2d(32, 64, 3, 1)
        self.dropout1 = nn.Dropout2d(0.25)
        self.dropout2 = nn.Dropout2d(0.5)
        #self.fc1 = nn.Linear(9216, 128)

    def forward(self, x):
        x = self.conv1(x)
        x = F.relu(x)
        x = self.conv2(x)
        x = F.relu(x)
        x = F.max_pool2d(x, 2)
        x = self.dropout1(x)
        x = torch.flatten(x, 1)
        #x = self.fc1(x)
        return x



def train(model, loss_func, mining_func, device, train_loader, optimizer, epoch):
    best_loss = 10
    model.train()
    for batch_idx, (data, labels) in enumerate(train_loader):
        data, labels = data.to(device), labels.to(device)
        optimizer.zero_grad()
        embeddings = model(data)
        indices_tuple = mining_func(embeddings, labels)
        loss = loss_func(embeddings, labels, indices_tuple)
        loss.backward()
        optimizer.step()
        if loss < best_loss: # for loss
            best_loss = loss
            torch.save(model.state_dict(), 'best_model_loss.pth')
        if batch_idx % 20 == 0:
            print(
                "Epoch {} Iteration {}: Loss = {}, Number of mined triplets = {}".format(
                    epoch, batch_idx, loss, mining_func.num_triplets
                )

            )


### convenient function from pytorch-metric-learning ###
def get_all_embeddings(dataset, model):
    tester = testers.BaseTester()
    return tester.get_all_embeddings(dataset, model)


### compute accuracy using AccuracyCalculator from pytorch-metric-learning ###
def test(train_set, test_set, model, accuracy_calculator):
    train_embeddings, train_labels = get_all_embeddings(train_set, model)
    test_embeddings, test_labels = get_all_embeddings(test_set, model)
    train_labels = train_labels.squeeze(1)
    test_labels = test_labels.squeeze(1)
    print("Computing accuracy")
    accuracies = accuracy_calculator.get_accuracy(
        test_embeddings, test_labels, train_embeddings, train_labels, False
    )
    print("Test set accuracy (Precision@1) = {}".format(accuracies["precision_at_1"]))
    
    return accuracies["precision_at_1"]


device = torch.device("cuda")

transform = transforms.Compose([
    transforms.RandomResizedCrop(224),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])
transformation_images = ResNet18_Weights.IMAGENET1K_V1.transforms()





def objective(trial):
    # Define the hyperparameters to be tuned
    lr = trial.suggest_loguniform("learning_rate", 1e-5, 1e-1)
    batch_size =    trial.suggest_categorical("batch_size", [16,24, 32, 64])

    dataset1 = datasets.ImageFolder(root="/media/michell/DSet/MIT_small_train_1/train/",transform=transformation_images)
    dataset2 = datasets.ImageFolder(root="/media/michell/DSet/MIT_small_train_1/test/",transform=transformation_images)
    
    train_loader = torch.utils.data.DataLoader(
        dataset1, batch_size=batch_size, shuffle=True
    )
    test_loader = torch.utils.data.DataLoader(dataset2, batch_size=batch_size)
    #model = Net().to(device)
    model1 = models.resnet18(weights = ResNet18_Weights.IMAGENET1K_V1)
    feature_extractor = torch.nn.Sequential(*(list(model1.children())[:-1]))
    model = nn.Sequential(feature_extractor, nn.Flatten()).to(device)
    
    optimizer = optim.Adam(model.parameters(), lr=lr)
    num_epochs = 50  
    ### pytorch-metric-learning stuff ###
    distance = distances.CosineSimilarity()
    reducer = reducers.ThresholdReducer(low=0)
    loss_func = losses.TripletMarginLoss(margin=0.2, distance=distance, reducer=reducer)
    mining_func = miners.TripletMarginMiner(
        margin=0.2, distance=distance, type_of_triplets="semihard"
    )
    accuracy_calculator = AccuracyCalculator(include=("precision_at_1",), k=1)
    ### pytorch-metric-learning stuff ###
    
    accuracy=0
    bestaccuracy=0
    for epoch in range(1, num_epochs + 1):
        train(model, loss_func, mining_func, device, train_loader, optimizer, epoch)
        accuracy =test(dataset1, dataset2, model, accuracy_calculator)
        if accuracy> bestaccuracy: 
            bestaccuracy=accuracy
    return bestaccuracy    
        
study = optuna.create_study(direction="maximize")
study.optimize(objective, n_trials=20)